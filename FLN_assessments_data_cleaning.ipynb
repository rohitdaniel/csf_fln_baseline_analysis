{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "21d30864",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a2599e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cleaning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ee281a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Rohit: 36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "de94717d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8694/1482412854.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'extract_name' is not defined"
     ]
    }
   ],
   "source": [
    "extract_name(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc1f04",
   "metadata": {},
   "source": [
    "# Merge raw data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae81d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory to folder with Tangerine raw data files\n",
    "# os.chdir(r'/home/rohitdaniel/Documents/Ei_CSF_FLN_Evaluation/SLO_Baseline/tangerine_files')\n",
    "        \n",
    "# Import the datasets that need to be merged\n",
    "# mp_raw_1 = pd.read_excel(\"./mp_raw_data_9-25 Sep_location_fixed_v5.xlsx\", index_col='_id')\n",
    "# mp_raw_2 = pd.read_csv(\"./CSF_FLN_2022_Grade_1_Baseline-CSF_FLN_Evaluation_MP_Baseline_2022_v2.19-1666664920923.csv\", index_col='_id', low_memory=False)\n",
    "\n",
    "# up_raw_1 = pd.read_excel(\"./up_raw_data_19-23 Sep_location_fixed_v2.xlsx\", index_col='_id')\n",
    "# up_raw_2 = pd.read_csv(\"./CSF_FLN_2022_Grade_1_Baseline-CSF_FLN_Evaluation_UP_Baseline_2022_v2.19-1666664936961.csv\", index_col='_id', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c615abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to check if all columns in dataset1 are present in dataset 2\n",
    "# all(col in mp_raw_2.columns for col in mp_raw_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b845aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_cols = set(mp_raw_1.columns).difference(set(mp_raw_2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b18d9b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename colmns in old CSV file to facilitate concatenation\n",
    "# old_cols = set(mp_raw_1.columns).difference(set(mp_raw_2.columns)) # Create list of columns that needs to be renamed\n",
    "\n",
    "# new_cols = [re.search('^.+(?=\\.\\w+$)', col).group(0) for col in old_cols] # Create list of new names for the columns\n",
    "\n",
    "# rename_cols = {} # Initialize dictionary to store old and new column names\n",
    "\n",
    "# for old_col, new_col in zip(old_cols, new_cols):\n",
    "#     rename_cols[old_col] = new_col\n",
    "\n",
    "# mp_raw_1.rename(columns=rename_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b6c61c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate both raw dataframes\n",
    "# mp_raw = pd.concat([mp_raw_1, mp_raw_2], join=\"inner\")\n",
    "# up_raw = pd.concat([up_raw_1, up_raw_2], join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b6b00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_fix_labels = {'school_details.UDISE_cd_label': {23310607203: 23310607101, 23310607802: 23310601105, 23310613802: 23310601104}, \\\n",
    "#                         'school_details.School_label': {'NMS SANKLA JAGTHAR': 'PS JAGTHAR', 'MS SANOTI':'EGS SALAIYAPURA', 'EGS TAPRA KACHHI': 'EGS KHARI TAPRA'}}\n",
    "\n",
    "# mp_mask_idx = mp_raw.index[mp_raw.assessment_date == '2022-10-10']\n",
    "# mp_raw.loc[mask_idx, :] = mp_raw.loc[mp_mask_idx, :].replace(mp_fix_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73c8e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# up_fix_labels = {'school_details.UDISE_cd_label': {9691406101: 9691405001}, \\\n",
    "#                  'school_details.School_label': {'P.S. SANDWA': 'P.S. DHAURUPUR'}}\n",
    "\n",
    "# up_mask = ((up_raw.assessment_date == '2022-10-21') & ((up_raw.tabletUserName == 'Munish')  | (up_raw.tabletUserName == 'Poonamkumari')))\n",
    "# up_mask_idx = up_raw.index[up_mask]\n",
    "\n",
    "# up_raw.loc[up_mask_idx, :] = up_raw.loc[up_mask_idx, :].replace(up_fix_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e1d9cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export concatenated dataframe to Excel file for further cleaning and analysis\n",
    "# mp_raw.to_excel(\"mp_raw_full.xlsx\")\n",
    "# up_raw.to_excel(\"up_raw_full.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30efec0c",
   "metadata": {},
   "source": [
    "# Data Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ab306377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDatetime(dataframe):\n",
    "    time_cols = [col for col in dataframe.columns if re.search(r'^(?!Submission).*(?!_)(?i)time$', col)]\n",
    "\n",
    "    for col in time_cols:\n",
    "        dataframe.loc[:, col] = dataframe.apply(lambda row: datetime.fromtimestamp(float(row[col])/1000) if not ((pd.isna(row[col])) | (row[col] == 'UNDEFINED') | (row[col] == 'SKIPPED')) else row[col], axis=1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "07dd16fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_or_scores(dataframe, other_responses):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cc58014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_treatment(dataframe, score_col):\n",
    "    iqr = np.percentile(dataframe[score_col], 75) - np.percentile(dataframe[score_col], 25)\n",
    "    outliers = dataframe[dataframe[score_col] >= 1.5*iqr]\n",
    "    return (outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706d84c",
   "metadata": {},
   "source": [
    "# Import merged raw data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0260949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory\n",
    "os.chdir(r'/home/rohitdaniel/Documents/CSF_FLN_Evaluation/SLO_Baseline/rawData')\n",
    "\n",
    "# Import concatenated raw dataframe for cleaning\n",
    "mp_raw = pd.read_excel(\"./mp_raw_full.xlsx\", index_col='_id')\n",
    "mp_raw.name = 'mp_raw'\n",
    "\n",
    "up_raw = pd.read_excel(\"./up_raw_full.xlsx\", index_col='_id', )\n",
    "up_raw.name = 'up_raw'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd9eff",
   "metadata": {},
   "source": [
    "## A. Literacy Sub-tasks Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "668df679",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_raw_lit, mp_raw_num = clean_data(mp_raw)\n",
    "mp_raw_lit.name = 'MP literacy'\n",
    "mp_raw_num.name = 'MP numeracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5f4663c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_raw_lit, up_raw_num = clean_data(up_raw)\n",
    "up_raw_lit.name = 'UP literacy'\n",
    "up_raw_num.name = 'UP numeracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0ea3740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    duration_cols = [col for col in dataframe.columns if re.search(r'.+time_remaining$', col)]\n",
    "    clean_scores(dataframe, duration_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c515b03",
   "metadata": {},
   "source": [
    "### Literacy 1: Listening Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0baf40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    lit1_raw = [col for col in dataframe.columns if re.search(r'literacy1_q\\d$', col)]\n",
    "#     print(f'\\033[1mCleaning literacy {dataframe.name} subtask 1 scores\\033[0m')\n",
    "    clean_scores(dataframe, lit1_raw)\n",
    "    \n",
    "    \n",
    "    # Calculate total score and percentage correct on listening comprehension sub-task\n",
    "    dataframe.loc[:, 'literacy1_total'] = dataframe.apply(lambda x: total_score([x[col] for col in lit1_raw]), axis=1)\n",
    "    dataframe.loc[:, 'literacy1_%_correct'] = dataframe.apply(lambda x: 100*x['literacy1_total']/len(lit1_raw), axis=1)\n",
    "    \n",
    "    # Extract other responses to listening comprehension questions\n",
    "    lit1_or = [col for col in dataframe.columns if re.search(r'^literacy1_\\S*or$', col)]\n",
    "    file_name = dataframe.name + '_lit1_or.xlsx'\n",
    "    with pd.ExcelWriter(file_name) as writer: \n",
    "        for col in lit1_or:\n",
    "            dataframe[col].value_counts().reset_index().rename(columns = {'index':\"Response\", col:'Frequency'}).to_excel(writer, sheet_name=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1447294b",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 2: Oral Vocabulary\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "76ded100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    lit2_raw = [col for col in dataframe.columns if re.search(r'literacy2_q\\d+$', col)]\n",
    "#     print(f'\\033[1mCleaning literacy {dataframe.name} subtask 2 scores\\033[0m')\n",
    "    clean_scores(dataframe, lit2_raw)\n",
    "        \n",
    "    dataframe.loc[:, 'literacy2_total'] = dataframe.apply(lambda x: total_score([x[col] for col in lit2_raw]), axis=1)\n",
    "    dataframe.loc[:, 'literacy2_%_correct'] = dataframe.apply(lambda x: 100*x['literacy2_total']/len(lit2_raw), axis=1)\n",
    "    \n",
    "    # Extract other responses to oral vocabulary questions\n",
    "    lit2_or = [col for col in dataframe.columns if re.search(r'literacy2\\S*or$', col)]\n",
    "    file_name = dataframe.name + '_lit2_or.xlsx'\n",
    "    with pd.ExcelWriter(file_name) as writer: \n",
    "        for col in lit2_or:\n",
    "            dataframe[col].value_counts().reset_index().rename(columns = {'index':\"Response\", col:'Frequency'}).to_excel(writer, sheet_name=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99538b38",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 3: Initial Sound Identification\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ca10182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    lit3_raw = [col for col in dataframe.columns if re.search(r'literacy3_q\\d+$', col)]\n",
    "#     print(f'\\033[1mCleaning literacy {dataframe.name} subtask 3 scores\\033[0m')\n",
    "    clean_scores(dataframe, lit3_raw)\n",
    "    \n",
    "    dataframe.loc[:, 'literacy3_total'] = dataframe.apply(lambda x: total_score([x[col] for col in lit3_raw]), axis=1)\n",
    "    dataframe.loc[:, 'literacy3_%_correct'] = dataframe.apply(lambda x: 100*x['literacy3_total']/len(lit3_raw), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbdf2e3",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 4: Letter Recognition (Untimed)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4064c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    lit4_ut_raw = [col for col in dataframe.columns if re.search(r'literacy4_ut_grid_\\d*$', col)]\n",
    "#     print(f'\\033[1mCleaning literacy {dataframe.name} subtask 4 (untimed) scores\\033[0m')\n",
    "    clean_scores(dataframe, lit4_ut_raw)\n",
    "    dataframe.loc[:, lit4_ut_raw] = pd.DataFrame((dataframe.apply(lambda x: fix_scores([x[col] for col in lit4_ut_raw]), axis=1)).to_list(), index=dataframe.index, columns=lit4_ut_raw)\n",
    "    \n",
    "    # Calculate total score on letter naming (untimed) sub-task\n",
    "    dataframe.loc[:, 'literacy4_ut_total'] = dataframe.apply(lambda x: total_score([x[score] for score in lit4_ut_raw]), axis=1)\n",
    "    dataframe.loc[:, 'literacy4_ut_%_correct'] = dataframe.apply(lambda x: 100*x['literacy4_ut_total']/len(lit4_ut_raw), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e898db",
   "metadata": {},
   "source": [
    "### Literacy 4: Letter Recognition (Timed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8bc5ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fluency_scores(dataframe, cols):\n",
    "    fluency = 0\n",
    "    score_cols = [col for col in cols if re.search(r'.+\\d$', col)]\n",
    "    total = total_score(dataframe[score_cols])\n",
    "    duration_col = [col for col in cols if re.search(r'.+time_remaining$', col)]\n",
    "    duration = (60 - int(dataframe[duration_col]))\n",
    "    if duration != 0:\n",
    "        fluency = ((60*total)/duration)\n",
    "    return fluency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fde54e58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8694/2300089415.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlit4_tt_scores\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfix_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlit4_tt_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlit4_tt_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Calculate automaticity on letter naming (timed) sub-task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'literacy4_tt_fluency'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfluency_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlit4_tt_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8846\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8847\u001b[0m         )\n\u001b[0;32m-> 8848\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8850\u001b[0m     def applymap(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8694/2300089415.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlit4_tt_scores\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfix_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlit4_tt_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlit4_tt_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Calculate automaticity on letter naming (timed) sub-task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'literacy4_tt_fluency'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfluency_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlit4_tt_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/CSF_FLN_Evaluation/SLO_Baseline/data_cleaning/fluency_score.py\u001b[0m in \u001b[0;36mfluency_score\u001b[0;34m(dataframe, cols)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfluency_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfluency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mscore_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'.+\\d$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mduration_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'.+time_remaining'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CSF_FLN_Evaluation/SLO_Baseline/data_cleaning/fluency_score.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfluency_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfluency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mscore_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'.+\\d$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mduration_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'.+time_remaining'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "# Check data for 'UNDEFINED' or 'SKIPPED' values\n",
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    lit4_tt_raw = [col for col in dataframe.columns if re.search(r'literacy4_tt.+', col)]\n",
    "    lit4_tt_scores = [col for col in dataframe.columns if re.search(r'literacy4_tt_grid_\\d+$', col)]\n",
    "\n",
    "    # print(f'\\033[1mCleaning literacy {dataframe.name} subtask 4 (timed) scores\\033[0m')\n",
    "    clean_scores(dataframe, lit4_tt_scores)\n",
    "    dataframe.loc[:, lit4_tt_scores] = pd.DataFrame((dataframe.apply(lambda x: fix_scores([x[col] for col in lit4_tt_scores]), axis=1)).to_list(), index=dataframe.index, columns=lit4_tt_scores)\n",
    "    # Calculate automaticity on letter naming (timed) sub-task\n",
    "    dataframe.loc[:, 'literacy4_tt_fluency'] = dataframe.apply(lambda x: fluency_score(x, lit4_tt_raw), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf0858",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 5: Familiar Words Reading (Untimed)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eef5fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data for 'UNDEFINED' or 'SKIPPED' values\n",
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    lit5_ut_raw = [col for col in dataframe.columns if re.search(r'literacy5_ut_grid_\\d*$', col)]\n",
    "#     print(f'\\033[1mCleaning literacy {dataframe.name} subtask 5 (untimed) scores\\033[0m')\n",
    "    clean_scores(dataframe, lit5_ut_raw)\n",
    "    dataframe.loc[:, lit5_ut_raw] = pd.DataFrame((dataframe.apply(lambda x: fix_scores([x[col] for col in lit5_ut_raw]), axis=1)).to_list(), index=dataframe.index, columns=lit5_ut_raw)\n",
    "    \n",
    "    dataframe.loc[:, 'literacy5_ut_total'] = dataframe.apply(lambda x: total_score([x[score] for score in lit5_ut_raw]), axis=1)\n",
    "    dataframe.loc[:, 'literacy5_ut_%_correct'] = dataframe.apply(lambda x: 100*x['literacy5_ut_total']/len(lit5_ut_raw), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bedc45",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 5: Familiar Words Reading (Timed)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbb6ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data for 'UNDEFINED' or 'SKIPPED' values\n",
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    lit5_tt_raw = [col for col in dataframe.columns if re.search(r'literacy5_tt.+', col)]\n",
    "    lit5_tt_scores = [col for col in dataframe.columns if re.search(r'literacy5_tt_grid_\\d+$', col)]\n",
    "\n",
    "    # print(f'\\033[1mCleaning literacy {dataframe.name} subtask 5 (timed) scores\\033[0m')\n",
    "    clean_scores(dataframe, lit5_tt_scores)\n",
    "    dataframe.loc[:, lit5_tt_scores] = pd.DataFrame((dataframe.apply(lambda x: fix_scores([x[col] for col in lit5_tt_scores]), axis=1)).to_list(), index=dataframe.index, columns=lit5_tt_scores)\n",
    "    \n",
    "    # Calculate automaticity on letter naming (timed) sub-task\n",
    "#     dataframe.loc[:, 'literacy5_tt_fluency'] = dataframe.apply(lambda x: fluency_score(x, lit5_tt_raw), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a8a8ed",
   "metadata": {},
   "source": [
    "### Literacy 6: Non-word Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b139ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data for 'UNDEFINED' or 'SKIPPED' values\n",
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    lit6_tt_raw = [col for col in dataframe.columns if re.search(r'literacy6_tt.+', col)]\n",
    "    lit6_tt_scores = [col for col in dataframe.columns if re.search(r'literacy6_tt_grid_\\d+$', col)]\n",
    "    #     print(f'\\033[1mCleaning literacy {dataframe.name} subtask 6 scores\\033[0m')\n",
    "    clean_scores(dataframe, lit6_tt_scores)\n",
    "    dataframe.loc[:, lit6_tt_scores] = pd.DataFrame((dataframe.apply(lambda x: fix_scores([x[col] for col in lit6_tt_scores]), axis=1)).to_list(), index=dataframe.index, columns=lit6_tt_scores)\n",
    "    \n",
    "    # Calculate automaticity on letter naming (timed) sub-task\n",
    "#     dataframe.loc[:, 'literacy6_tt_fluency'] = dataframe.apply(lambda x: fluency_score(x, lit6_tt_raw), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565f8552",
   "metadata": {},
   "source": [
    "### Literacy 7: Oral Reading Fluency (Timed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "edc708eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data for 'UNDEFINED' or 'SKIPPPED' values\n",
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    lit7_raw = [col for col in dataframe.columns if re.search(r'literacy7_tt.+', col)]\n",
    "    lit7_scores = [col for col in dataframe.columns if re.search(r'literacy7_tt_grid_\\d+$', col)]\n",
    "    \n",
    "#     print(f'\\033[1mCleaning literacy {dataframe.name} subtask 7 scores\\033[0m')\n",
    "    clean_scores(dataframe, lit7_scores)\n",
    "    dataframe.loc[:, lit7_scores] = pd.DataFrame((dataframe.apply(lambda x: fix_scores([x[col] for col in lit7_scores]), axis=1)).to_list(), index=dataframe.index, columns=lit7_scores)\n",
    "    \n",
    "     # Calculate automaticity on letter naming (timed) sub-task\n",
    "#     dataframe.loc[:, 'literacy7_tt_fluency'] = dataframe.apply(lambda x: fluency_score(x, lit7_raw), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf897678",
   "metadata": {},
   "source": [
    "### Literacy 8: Reading Comprehension (Untimed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d58965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data for 'UNDEFINED' or 'SKIPPPED' values\n",
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    lit8_raw_reading = [col for col in dataframe.columns if re.search(r'literacy8_ut_grid_\\d*$', col)]\n",
    "    lit8_raw_comprehension = [col for col in dataframe.columns if re.search(r'literacy8_ut_q\\d*$', col)]\n",
    "#     print(f'\\033[1mCleaning literacy {dataframe.name} subtask 8 scores\\033[0m')\n",
    "    for scores in [lit8_raw_reading, lit8_raw_comprehension]:\n",
    "        clean_scores(dataframe, scores)\n",
    "    dataframe.loc[:, lit8_raw_reading] = pd.DataFrame((dataframe.apply(lambda x: fix_scores([x[col] for col in lit8_raw_reading]), axis=1)).to_list(), index=dataframe.index, columns=lit8_raw_reading)\n",
    "    \n",
    "    dataframe.loc[:, 'literacy8_reading_total'] = dataframe.apply(lambda x: total_score([x[score] for score in lit8_raw_reading]), axis=1)\n",
    "    dataframe.loc[:, 'literacy8_reading_%_correct'] = dataframe.apply(lambda x: 100*x['literacy8_reading_total']/len(lit8_raw_reading), axis=1)\n",
    "    dataframe.loc[:, 'literacy8_comprehension_total'] = dataframe.apply(lambda x: total_score([x[score] for score in lit8_raw_comprehension]), axis=1)\n",
    "    dataframe.loc[:, 'literacy8_comprehension_%_correct'] = dataframe.apply(lambda x: 100*x['literacy8_comprehension_total']/len(lit8_raw_comprehension), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b484360c",
   "metadata": {},
   "source": [
    "### Literacy 9a: Dictation (Letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd09711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data for 'UNDEFINED' or 'SKIPPPED' values\n",
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    lit9a_raw = [col for col in dataframe.columns if re.search(r'literacy9a_ut_grid_\\d*', col)]\n",
    "#     print(f'\\033[1mCleaning literacy {dataframe.name} subtask 9a scores\\033[0m')\n",
    "    clean_scores(dataframe, lit9a_raw)\n",
    "    dataframe.loc[:, lit9a_raw] = pd.DataFrame((dataframe.apply(lambda x: fix_scores([x[col] for col in lit9a_raw]), axis=1)).to_list(), index=dataframe.index, columns=lit9a_raw)\n",
    "    dataframe.loc[:, 'literacy9a_total'] = dataframe.apply(lambda x: total_score([x[score] for score in lit9a_raw]), axis=1)\n",
    "    dataframe.loc[:, 'literacy9a_%_correct'] = dataframe.apply(lambda x: 100*x['literacy9a_total']/len(lit9a_raw), axis=1)\n",
    "    # dataframe.loc[:, 'literacy9a_total'] = dataframe.apply(lambda x: validated_scores(x, mp_validated), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9cd92d4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mp_dictation_letters_validation = mp_raw_lit[mp_raw_lit.literacy9a_total >= 5][['assessment_date', 'school_details.State_label', 'school_details.District_label', \\\n",
    "                                              'school_details.Block_label', 'school_details.School_label', \\\n",
    "                                              'school_details.UDISE_cd_label', 'SI_std_name', 'GI_std_name', 'student_age', \\\n",
    "                                              'student_gender', 'literacy9a_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0cbe4bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_dictation_letters_validation = up_raw_lit[up_raw_lit.literacy9a_total >= 5][['assessment_date', 'school_details.State_label', 'school_details.District_label', \\\n",
    "                                              'school_details.Block_label', 'school_details.School_label', \\\n",
    "                                              'school_details.UDISE_cd_label', 'SI_std_name', 'GI_std_name', 'student_age', \\\n",
    "                                              'student_gender', 'literacy9a_total']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b15e80",
   "metadata": {},
   "source": [
    "### Literacy 9b: Dictation (Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "812b56e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check data for 'UNDEFINED' or 'SKIPPPED' values\n",
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    lit9b_raw = [col for col in dataframe.columns if re.search(r'literacy9b_ut_grid_\\d*', col)]\n",
    "#     print(f'\\033[1mCleaning literacy {dataframe.name} subtask 9b scores\\033[0m')\n",
    "    clean_scores(dataframe, lit9b_raw)\n",
    "    dataframe.loc[:, lit9b_raw] = pd.DataFrame((dataframe.apply(lambda x: fix_scores([x[col] for col in lit9b_raw]), axis=1)).to_list(), index=dataframe.index, columns=lit9b_raw)\n",
    "    \n",
    "    dataframe.loc[:, 'literacy9b_total'] = dataframe.apply(lambda x: total_score([x[score] for score in lit9b_raw]), axis=1)\n",
    "    dataframe.loc[:, 'literacy9b_%_correct'] = dataframe.apply(lambda x: 100*x['literacy9b_total']/len(lit9b_raw), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abf32e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_dictation_words_validation = mp_raw_lit[mp_raw_lit.literacy9b_total >= 5][['assessment_date', 'school_details.State_label', 'school_details.District_label', \\\n",
    "                                              'school_details.Block_label', 'school_details.School_label', \\\n",
    "                                              'school_details.UDISE_cd_label', 'SI_std_name', 'GI_std_name', 'student_age', \\\n",
    "                                              'student_gender', 'literacy9b_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e58faea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_dictation_words_validation = up_raw_lit[up_raw_lit.literacy9b_total >= 5][['assessment_date', 'school_details.State_label', 'school_details.District_label', \\\n",
    "                                              'school_details.Block_label', 'school_details.School_label', \\\n",
    "                                              'school_details.UDISE_cd_label', 'SI_std_name', 'GI_std_name', 'student_age', \\\n",
    "                                              'student_gender', 'literacy9b_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "440c079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_dictation_validation = pd.merge(left=mp_dictation_letters_validation, right=mp_dictation_words_validation, how='outer')\n",
    "mp_dictation_validation.to_excel('mp_dictation_validation.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89a238f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohitdaniel/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:916: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  key_col = Index(lvals).where(~mask_left, rvals)\n"
     ]
    }
   ],
   "source": [
    "up_dictation_validation = pd.merge(left=up_dictation_letters_validation, right=up_dictation_words_validation, how='outer')\n",
    "up_dictation_validation.to_excel('up_dictation_validation.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e79de7bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['literacy4_tt_fluency', 'literacy5_tt_fluency', 'literacy6_tt_fluency', 'literacy7_tt_fluency'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8694/1748139417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmp_raw_lit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_raw_lit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_cleaned.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m             \u001b[0;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1192\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1134\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5794\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5796\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5798\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5858\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5859\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5861\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['literacy4_tt_fluency', 'literacy5_tt_fluency', 'literacy6_tt_fluency', 'literacy7_tt_fluency'] not in index\""
     ]
    }
   ],
   "source": [
    "for dataframe in [mp_raw_lit, up_raw_lit]:\n",
    "    file_name = dataframe.name + '_cleaned.xlsx'\n",
    "    dataframe.loc[:, cols].to_excel(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "62360dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_raw_lit['student_gender'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f76f6",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    B. Numeracy Sub-tasks Data Cleaning\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b151fc6",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 1: Counting\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75e66095",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCleaning numeracy MP numeracy subtask 1 (timed) scores\u001b[0m\n",
      "No. of NaN values in numeracy1_tt_grid_1 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_1 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_1 = 0\n",
      "Unique values in numeracy1_tt_grid_1 = ['1' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_2 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_2 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_2 = 0\n",
      "Unique values in numeracy1_tt_grid_2 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_3 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_3 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_3 = 0\n",
      "Unique values in numeracy1_tt_grid_3 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_4 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_4 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_4 = 0\n",
      "Unique values in numeracy1_tt_grid_4 = ['1' '0' '999']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_5 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_5 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_5 = 0\n",
      "Unique values in numeracy1_tt_grid_5 = ['1' '0' '999']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_6 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_6 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_6 = 0\n",
      "Unique values in numeracy1_tt_grid_6 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_7 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_7 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_7 = 0\n",
      "Unique values in numeracy1_tt_grid_7 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_8 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_8 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_8 = 0\n",
      "Unique values in numeracy1_tt_grid_8 = ['1' '0' '999']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_9 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_9 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_9 = 0\n",
      "Unique values in numeracy1_tt_grid_9 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_10 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_10 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_10 = 0\n",
      "Unique values in numeracy1_tt_grid_10 = ['0' '1' '999']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_11 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_11 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_11 = 0\n",
      "Unique values in numeracy1_tt_grid_11 = ['999' '1' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_12 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_12 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_12 = 0\n",
      "Unique values in numeracy1_tt_grid_12 = ['999' '1' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_13 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_13 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_13 = 0\n",
      "Unique values in numeracy1_tt_grid_13 = ['999' '1' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_14 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_14 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_14 = 0\n",
      "Unique values in numeracy1_tt_grid_14 = ['999' '1' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_15 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_15 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_15 = 0\n",
      "Unique values in numeracy1_tt_grid_15 = ['999' '1' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_16 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_16 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_16 = 0\n",
      "Unique values in numeracy1_tt_grid_16 = ['999' '1' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_17 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_17 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_17 = 0\n",
      "Unique values in numeracy1_tt_grid_17 = ['999' '1' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_18 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_18 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_18 = 0\n",
      "Unique values in numeracy1_tt_grid_18 = ['999' '1' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_19 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_19 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_19 = 0\n",
      "Unique values in numeracy1_tt_grid_19 = ['999' '1' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_20 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_20 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_20 = 0\n",
      "Unique values in numeracy1_tt_grid_20 = ['999' '1' '0']\n",
      "\n",
      "\u001b[1mCleaning numeracy UP numeracy subtask 1 (timed) scores\u001b[0m\n",
      "No. of NaN values in numeracy1_tt_grid_1 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_1 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_1 = 0\n",
      "Unique values in numeracy1_tt_grid_1 = ['1' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_2 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_2 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_2 = 0\n",
      "Unique values in numeracy1_tt_grid_2 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_3 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_3 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_3 = 0\n",
      "Unique values in numeracy1_tt_grid_3 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_4 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_4 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_4 = 0\n",
      "Unique values in numeracy1_tt_grid_4 = ['1' '0' '999']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_5 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_5 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_5 = 0\n",
      "Unique values in numeracy1_tt_grid_5 = ['1' '0' '999']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_6 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_6 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_6 = 0\n",
      "Unique values in numeracy1_tt_grid_6 = ['1' '0' '999']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_7 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_7 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_7 = 0\n",
      "Unique values in numeracy1_tt_grid_7 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_8 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_8 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_8 = 0\n",
      "Unique values in numeracy1_tt_grid_8 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_9 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_9 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_9 = 0\n",
      "Unique values in numeracy1_tt_grid_9 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_10 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_10 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_10 = 0\n",
      "Unique values in numeracy1_tt_grid_10 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_11 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_11 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_11 = 0\n",
      "Unique values in numeracy1_tt_grid_11 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_12 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_12 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_12 = 0\n",
      "Unique values in numeracy1_tt_grid_12 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_13 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_13 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_13 = 0\n",
      "Unique values in numeracy1_tt_grid_13 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_14 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_14 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_14 = 0\n",
      "Unique values in numeracy1_tt_grid_14 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_15 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_15 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_15 = 0\n",
      "Unique values in numeracy1_tt_grid_15 = ['1' '0' '999']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_16 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_16 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_16 = 0\n",
      "Unique values in numeracy1_tt_grid_16 = ['1' '0' '999']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_17 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_17 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_17 = 0\n",
      "Unique values in numeracy1_tt_grid_17 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_18 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_18 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_18 = 0\n",
      "Unique values in numeracy1_tt_grid_18 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_19 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_19 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_19 = 0\n",
      "Unique values in numeracy1_tt_grid_19 = ['1' '999' '0']\n",
      "\n",
      "No. of NaN values in numeracy1_tt_grid_20 = 0\n",
      "No. of UNDEFINED values in numeracy1_tt_grid_20 = 0\n",
      "No. of SKIPPED values in numeracy1_tt_grid_20 = 0\n",
      "Unique values in numeracy1_tt_grid_20 = ['0' '1' '999']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "for dataframe in [mp_raw_num, up_raw_num]:\n",
    "    num1_raw = [col for col in dataframe.columns if re.search(r'numeracy1_tt_grid_\\d*$', col)]\n",
    "    print(f'\\033[1mCleaning numeracy {dataframe.name} subtask 1 (timed) scores\\033[0m')\n",
    "    clean_scores(num1_raw, dataframe)\n",
    "    dataframe.loc[:, num1_raw] = pd.DataFrame((dataframe.apply(lambda x: fix_counting_score([x[col] for col in num1_raw]), axis=1)).to_list(), index=dataframe.index, columns=num1_raw)\n",
    "    \n",
    "#     dataframe.loc[:, 'literacy5_ut_total'] = dataframe.apply(lambda x: total_score([x[score] for score in lit5_ut_raw]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc53deca",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 2: Number Recognition (Untimed)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4deaeb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCleaning numeracy MP numeracy subtask 2 (untimed) scores\u001b[0m\n",
      "No. of NaN values in numeracy2_ut_grid_1 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_1 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_1 = 0\n",
      "Unique values in numeracy2_ut_grid_1 = ['0' '1']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_2 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_2 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_2 = 0\n",
      "Unique values in numeracy2_ut_grid_2 = ['0' '1']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_3 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_3 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_3 = 0\n",
      "Unique values in numeracy2_ut_grid_3 = ['0' '1']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_4 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_4 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_4 = 0\n",
      "Unique values in numeracy2_ut_grid_4 = ['0' '1' '999']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_5 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_5 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_5 = 0\n",
      "Unique values in numeracy2_ut_grid_5 = ['999' '1' '0']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_6 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_6 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_6 = 0\n",
      "Unique values in numeracy2_ut_grid_6 = ['999' '1' '0']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_7 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_7 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_7 = 0\n",
      "Unique values in numeracy2_ut_grid_7 = ['999' '1' '0']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_8 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_8 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_8 = 0\n",
      "Unique values in numeracy2_ut_grid_8 = ['999' '0' '1']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_9 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_9 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_9 = 0\n",
      "Unique values in numeracy2_ut_grid_9 = ['999' '0' '1']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_10 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_10 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_10 = 0\n",
      "Unique values in numeracy2_ut_grid_10 = ['999' '0' '1']\n",
      "\n",
      "\u001b[1mCleaning numeracy UP numeracy subtask 2 (untimed) scores\u001b[0m\n",
      "No. of NaN values in numeracy2_ut_grid_1 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_1 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_1 = 0\n",
      "Unique values in numeracy2_ut_grid_1 = ['1' '0']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_2 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_2 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_2 = 0\n",
      "Unique values in numeracy2_ut_grid_2 = ['0' '1']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_3 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_3 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_3 = 0\n",
      "Unique values in numeracy2_ut_grid_3 = ['0' '1']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_4 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_4 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_4 = 0\n",
      "Unique values in numeracy2_ut_grid_4 = ['1' '0' '999']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_5 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_5 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_5 = 0\n",
      "Unique values in numeracy2_ut_grid_5 = ['1' '0' '999']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_6 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_6 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_6 = 0\n",
      "Unique values in numeracy2_ut_grid_6 = ['0' '999' '1']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_7 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_7 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_7 = 0\n",
      "Unique values in numeracy2_ut_grid_7 = ['0' '1' '999']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_8 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_8 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_8 = 0\n",
      "Unique values in numeracy2_ut_grid_8 = ['1' '0' '999']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_9 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_9 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_9 = 0\n",
      "Unique values in numeracy2_ut_grid_9 = ['1' '0' '999']\n",
      "\n",
      "No. of NaN values in numeracy2_ut_grid_10 = 0\n",
      "No. of UNDEFINED values in numeracy2_ut_grid_10 = 0\n",
      "No. of SKIPPED values in numeracy2_ut_grid_10 = 0\n",
      "Unique values in numeracy2_ut_grid_10 = ['1' '999' '0']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "for dataframe in [mp_raw_num, up_raw_num]:\n",
    "    num2_ut_raw = [col for col in dataframe.columns if re.search(r'numeracy2_ut_grid_\\d*$', col)]\n",
    "    print(f'\\033[1mCleaning numeracy {dataframe.name} subtask 2 (untimed) scores\\033[0m')\n",
    "    clean_scores(num2_ut_raw, dataframe)\n",
    "    dataframe.loc[:, num2_ut_raw] = pd.DataFrame((dataframe.apply(lambda x: fix_score([x[col] for col in num2_ut_raw]), axis=1)).to_list(), index=dataframe.index, columns=num2_ut_raw)\n",
    "    \n",
    "    dataframe.loc[:, 'numeracy2_ut_total'] = dataframe.apply(lambda x: total_score([x[score] for score in num2_ut_raw]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98a96a",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 2: Number Recognition (Timed)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c6c5b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in numeracy2_tt_grid_1 = ['0' '1' 1 0]\n",
      "No. of NaN values in numeracy2_tt_grid_1 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_1 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_1 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_2 = ['0' '1' '.']\n",
      "No. of NaN values in numeracy2_tt_grid_2 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_2 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_2 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_3 = ['0' '1' '.']\n",
      "No. of NaN values in numeracy2_tt_grid_3 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_3 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_3 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_4 = ['0' '1' '.']\n",
      "No. of NaN values in numeracy2_tt_grid_4 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_4 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_4 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_5 = ['.' '1' '0']\n",
      "No. of NaN values in numeracy2_tt_grid_5 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_5 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_5 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_6 = ['.' '1' '0']\n",
      "No. of NaN values in numeracy2_tt_grid_6 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_6 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_6 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_7 = ['.' '1' '0']\n",
      "No. of NaN values in numeracy2_tt_grid_7 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_7 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_7 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_8 = ['.' '1' '0']\n",
      "No. of NaN values in numeracy2_tt_grid_8 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_8 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_8 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_9 = ['.' '1' '0']\n",
      "No. of NaN values in numeracy2_tt_grid_9 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_9 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_9 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_10 = ['.' '1' '0']\n",
      "No. of NaN values in numeracy2_tt_grid_10 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_10 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_10 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_11 = ['.' '1' '0']\n",
      "No. of NaN values in numeracy2_tt_grid_11 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_11 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_11 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_12 = ['.' '1' '0']\n",
      "No. of NaN values in numeracy2_tt_grid_12 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_12 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_12 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_13 = ['.' '1' '0']\n",
      "No. of NaN values in numeracy2_tt_grid_13 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_13 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_13 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_14 = ['.' '1' '0']\n",
      "No. of NaN values in numeracy2_tt_grid_14 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_14 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_14 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_15 = ['.' '0' '1']\n",
      "No. of NaN values in numeracy2_tt_grid_15 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_15 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_15 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_16 = ['.' '1' '0']\n",
      "No. of NaN values in numeracy2_tt_grid_16 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_16 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_16 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_17 = ['.' '0' '1']\n",
      "No. of NaN values in numeracy2_tt_grid_17 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_17 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_17 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_18 = ['.' '1' '0']\n",
      "No. of NaN values in numeracy2_tt_grid_18 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_18 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_18 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_19 = ['.' '0' '1']\n",
      "No. of NaN values in numeracy2_tt_grid_19 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_19 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_19 = 0\n",
      "\n",
      "Unique values in numeracy2_tt_grid_20 = ['.' '0' '1']\n",
      "No. of NaN values in numeracy2_tt_grid_20 = 0\n",
      "No. of UNDEFINED values in numeracy2_tt_grid_20 = 0\n",
      "No. of SKIPPED values in numeracy2_tt_grid_20 = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "for dataframe in [mp_raw_num, up_raw_num]:\n",
    "    num2_ut_raw = [col for col in dataframe.columns if re.search(r'numeracy2_ut_grid_\\d*$', col)]\n",
    "    print(f'\\033[1mCleaning numeracy {dataframe.name} subtask 2 (untimed) scores\\033[0m')\n",
    "    clean_scores(num2_ut_raw, dataframe)\n",
    "    dataframe.loc[:, num2_ut_raw] = pd.DataFrame((dataframe.apply(lambda x: fix_score([x[col] for col in num2_ut_raw]), axis=1)).to_list(), index=dataframe.index, columns=num2_ut_raw)\n",
    "    \n",
    "    dataframe.loc[:, 'numeracy2_ut_total'] = dataframe.apply(lambda x: total_score([x[score] for score in num2_ut_raw]), axis=1)\n",
    "numeracy2_tt_raw = [col for col in numeracy2_tt if re.search(r'numeracy2_tt_grid_', col)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a01dcc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_numeracy.loc[:, numeracy2_tt_raw] = pd.DataFrame((mp_numeracy.apply(lambda x: fix_score([x[col] for col in numeracy2_tt_raw]), axis=1)).to_list(), index=mp_numeracy.index, columns=numeracy2_tt_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0801fb9",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 3: Number Comparison\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19d6aa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in numeracy3_ut_q1 = ['1' '0' '88' 1 0]\n",
      "No. of NaN values in numeracy3_ut_q1 = 0\n",
      "No. of UNDEFINED values in numeracy3_ut_q1 = 0\n",
      "No. of SKIPPED values in numeracy3_ut_q1 = 0\n",
      "\n",
      "Unique values in numeracy3_ut_q2 = ['0' '1' '88' 1 0]\n",
      "No. of NaN values in numeracy3_ut_q2 = 0\n",
      "No. of UNDEFINED values in numeracy3_ut_q2 = 0\n",
      "No. of SKIPPED values in numeracy3_ut_q2 = 0\n",
      "\n",
      "Unique values in numeracy3_ut_q3 = ['1' '88' '0' 0 1]\n",
      "No. of NaN values in numeracy3_ut_q3 = 0\n",
      "No. of UNDEFINED values in numeracy3_ut_q3 = 0\n",
      "No. of SKIPPED values in numeracy3_ut_q3 = 0\n",
      "\n",
      "Unique values in numeracy3_ut_q4 = ['1' '0' '88' 0 1]\n",
      "No. of NaN values in numeracy3_ut_q4 = 0\n",
      "No. of UNDEFINED values in numeracy3_ut_q4 = 0\n",
      "No. of SKIPPED values in numeracy3_ut_q4 = 0\n",
      "\n",
      "Unique values in numeracy3_ut_q5 = ['1' '0' nan '88' 0 1]\n",
      "No. of NaN values in numeracy3_ut_q5 = 339\n",
      "No. of UNDEFINED values in numeracy3_ut_q5 = 0\n",
      "No. of SKIPPED values in numeracy3_ut_q5 = 0\n",
      "\n",
      "Unique values in numeracy3_ut_q6 = ['0' '1' nan '88' 0 1]\n",
      "No. of NaN values in numeracy3_ut_q6 = 433\n",
      "No. of UNDEFINED values in numeracy3_ut_q6 = 0\n",
      "No. of SKIPPED values in numeracy3_ut_q6 = 0\n",
      "\n",
      "Unique values in numeracy3_ut_q7 = ['1' '0' nan '88' 1 0]\n",
      "No. of NaN values in numeracy3_ut_q7 = 493\n",
      "No. of UNDEFINED values in numeracy3_ut_q7 = 0\n",
      "No. of SKIPPED values in numeracy3_ut_q7 = 0\n",
      "\n",
      "Unique values in numeracy3_ut_q8 = ['1' '0' nan '88' 1 0]\n",
      "No. of NaN values in numeracy3_ut_q8 = 547\n",
      "No. of UNDEFINED values in numeracy3_ut_q8 = 0\n",
      "No. of SKIPPED values in numeracy3_ut_q8 = 0\n",
      "\n",
      "Unique values in numeracy3_ut_q9 = ['1' '0' nan '88' 1 0]\n",
      "No. of NaN values in numeracy3_ut_q9 = 582\n",
      "No. of UNDEFINED values in numeracy3_ut_q9 = 0\n",
      "No. of SKIPPED values in numeracy3_ut_q9 = 0\n",
      "\n",
      "Unique values in numeracy3_ut_q10 = ['0' '1' nan '88' 1 0 88]\n",
      "No. of NaN values in numeracy3_ut_q10 = 631\n",
      "No. of UNDEFINED values in numeracy3_ut_q10 = 0\n",
      "No. of SKIPPED values in numeracy3_ut_q10 = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "for col in numeracy3:\n",
    "    print(f\"Unique values in {col} = {mp_numeracy[col].unique()}\")\n",
    "    print(f\"No. of NaN values in {col} = {mp_numeracy.loc[:, col].isna().sum()}\")\n",
    "    print(f\"No. of UNDEFINED values in {col} = {mp_numeracy[mp_numeracy[col] == 'UNDEFINED'].shape[0]}\")    \n",
    "    print(f\"No. of SKIPPED values in {col} = {mp_numeracy[mp_numeracy[col] == 'SKIPPED'].shape[0]}\\n\")\n",
    "    mp_numeracy.loc[:, col].fillna('999', inplace=True)\n",
    "    mp_numeracy[col].replace('UNDEFINED', '999', inplace=True)\n",
    "    mp_numeracy[col].replace('SKIPPED', '999', inplace=True)\n",
    "    mp_numeracy[col].replace('.', '999', inplace=True)\n",
    "    mp_numeracy.loc[:, col] = mp_numeracy.loc[:, col].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17f16b9",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 4: Counting in Bundles\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "135f915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in numeracy4_ut_q1 = ['0' '1' '88' 0 88 1]\n",
      "No. of NaN values in numeracy4_ut_q1 = 0\n",
      "No. of UNDEFINED values in numeracy4_ut_q1 = 0\n",
      "No. of SKIPPED values in numeracy4_ut_q1 = 0\n",
      "\n",
      "Unique values in numeracy4_ut_q2 = ['88' '0' '1' 0 88]\n",
      "No. of NaN values in numeracy4_ut_q2 = 0\n",
      "No. of UNDEFINED values in numeracy4_ut_q2 = 0\n",
      "No. of SKIPPED values in numeracy4_ut_q2 = 0\n",
      "\n",
      "Unique values in numeracy4_ut_q3 = ['88' '0' '1' 0 1 88]\n",
      "No. of NaN values in numeracy4_ut_q3 = 0\n",
      "No. of UNDEFINED values in numeracy4_ut_q3 = 0\n",
      "No. of SKIPPED values in numeracy4_ut_q3 = 0\n",
      "\n",
      "Unique values in numeracy4_ut_q4 = ['88' '0' '1' 0 88]\n",
      "No. of NaN values in numeracy4_ut_q4 = 0\n",
      "No. of UNDEFINED values in numeracy4_ut_q4 = 0\n",
      "No. of SKIPPED values in numeracy4_ut_q4 = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "numeracy4_raw = [col for col in numeracy4 if re.search(r'numeracy4.+\\d$', col)]\n",
    "for col in numeracy4_raw:\n",
    "    print(f\"Unique values in {col} = {mp_numeracy[col].unique()}\")\n",
    "    print(f\"No. of NaN values in {col} = {mp_numeracy.loc[:, col].isna().sum()}\")\n",
    "    print(f\"No. of UNDEFINED values in {col} = {mp_numeracy[mp_numeracy[col] == 'UNDEFINED'].shape[0]}\")    \n",
    "    print(f\"No. of SKIPPED values in {col} = {mp_numeracy[mp_numeracy[col] == 'SKIPPED'].shape[0]}\\n\")\n",
    "    mp_numeracy.loc[:, col].fillna('999', inplace=True)\n",
    "    mp_numeracy[col].replace('UNDEFINED', '999', inplace=True)\n",
    "    mp_numeracy[col].replace('SKIPPED', '999', inplace=True)\n",
    "    mp_numeracy[col].replace('.', '999', inplace=True)\n",
    "    mp_numeracy.loc[:, col] = mp_numeracy.loc[:, col].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de768162",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 5: Missing Numbers\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e4cf44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in numeracy5_ut_q1 = ['88' '1' '0' 1 88 0]\n",
      "No. of NaN values in numeracy5_ut_q1 = 0\n",
      "No. of UNDEFINED values in numeracy5_ut_q1 = 0\n",
      "No. of SKIPPED values in numeracy5_ut_q1 = 0\n",
      "\n",
      "Unique values in numeracy5_ut_q2 = ['88' '1' '0' 88 0]\n",
      "No. of NaN values in numeracy5_ut_q2 = 0\n",
      "No. of UNDEFINED values in numeracy5_ut_q2 = 0\n",
      "No. of SKIPPED values in numeracy5_ut_q2 = 0\n",
      "\n",
      "Unique values in numeracy5_ut_q3 = ['88' '1' '0' 1 88 0]\n",
      "No. of NaN values in numeracy5_ut_q3 = 0\n",
      "No. of UNDEFINED values in numeracy5_ut_q3 = 0\n",
      "No. of SKIPPED values in numeracy5_ut_q3 = 0\n",
      "\n",
      "Unique values in numeracy5_ut_q4 = ['88' '0' '1' 0 88 1]\n",
      "No. of NaN values in numeracy5_ut_q4 = 0\n",
      "No. of UNDEFINED values in numeracy5_ut_q4 = 0\n",
      "No. of SKIPPED values in numeracy5_ut_q4 = 0\n",
      "\n",
      "Unique values in numeracy5_ut_q5 = [nan '0' '1' '88' 88 0]\n",
      "No. of NaN values in numeracy5_ut_q5 = 1098\n",
      "No. of UNDEFINED values in numeracy5_ut_q5 = 0\n",
      "No. of SKIPPED values in numeracy5_ut_q5 = 0\n",
      "\n",
      "Unique values in numeracy5_ut_q6 = [nan '0' '88' '1' 0]\n",
      "No. of NaN values in numeracy5_ut_q6 = 1201\n",
      "No. of UNDEFINED values in numeracy5_ut_q6 = 0\n",
      "No. of SKIPPED values in numeracy5_ut_q6 = 0\n",
      "\n",
      "Unique values in numeracy5_ut_q7 = [nan '0' '88' '1' 0]\n",
      "No. of NaN values in numeracy5_ut_q7 = 1251\n",
      "No. of UNDEFINED values in numeracy5_ut_q7 = 0\n",
      "No. of SKIPPED values in numeracy5_ut_q7 = 0\n",
      "\n",
      "Unique values in numeracy5_ut_q8 = [nan '0' '88' '1' 0]\n",
      "No. of NaN values in numeracy5_ut_q8 = 1307\n",
      "No. of UNDEFINED values in numeracy5_ut_q8 = 0\n",
      "No. of SKIPPED values in numeracy5_ut_q8 = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "numeracy5_raw = [col for col in numeracy5 if re.search(r'numeracy5.+\\d$', col)]\n",
    "for col in numeracy5_raw:\n",
    "    print(f\"Unique values in {col} = {mp_numeracy[col].unique()}\")\n",
    "    print(f\"No. of NaN values in {col} = {mp_numeracy.loc[:, col].isna().sum()}\")\n",
    "    print(f\"No. of UNDEFINED values in {col} = {mp_numeracy[mp_numeracy[col] == 'UNDEFINED'].shape[0]}\")    \n",
    "    print(f\"No. of SKIPPED values in {col} = {mp_numeracy[mp_numeracy[col] == 'SKIPPED'].shape[0]}\\n\")\n",
    "    mp_numeracy.loc[:, col].fillna('999', inplace=True)\n",
    "    mp_numeracy[col].replace('UNDEFINED', '999', inplace=True)\n",
    "    mp_numeracy[col].replace('SKIPPED', '999', inplace=True)\n",
    "    mp_numeracy[col].replace('.', '999', inplace=True)\n",
    "    mp_numeracy.loc[:, col] = mp_numeracy.loc[:, col].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2de4f",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 6: Addition\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a0af6b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in numeracy6_ut_q1 = ['88' '1' '0' 0 88 1]\n",
      "No. of NaN values in numeracy6_ut_q1 = 0\n",
      "No. of UNDEFINED values in numeracy6_ut_q1 = 0\n",
      "No. of SKIPPED values in numeracy6_ut_q1 = 0\n",
      "\n",
      "Unique values in numeracy6_ut_q2 = ['88' '0' '1' 0 88]\n",
      "No. of NaN values in numeracy6_ut_q2 = 0\n",
      "No. of UNDEFINED values in numeracy6_ut_q2 = 0\n",
      "No. of SKIPPED values in numeracy6_ut_q2 = 0\n",
      "\n",
      "Unique values in numeracy6_ut_q3 = ['88' '1' '0' 1 88 0]\n",
      "No. of NaN values in numeracy6_ut_q3 = 0\n",
      "No. of UNDEFINED values in numeracy6_ut_q3 = 0\n",
      "No. of SKIPPED values in numeracy6_ut_q3 = 0\n",
      "\n",
      "Unique values in numeracy6_ut_q4 = ['88' '1' '0' 0 88 1]\n",
      "No. of NaN values in numeracy6_ut_q4 = 0\n",
      "No. of UNDEFINED values in numeracy6_ut_q4 = 0\n",
      "No. of SKIPPED values in numeracy6_ut_q4 = 0\n",
      "\n",
      "Unique values in numeracy6_ut_q5 = [nan '1' '88' '0' 0 88]\n",
      "No. of NaN values in numeracy6_ut_q5 = 972\n",
      "No. of UNDEFINED values in numeracy6_ut_q5 = 0\n",
      "No. of SKIPPED values in numeracy6_ut_q5 = 0\n",
      "\n",
      "Unique values in numeracy6_ut_q6 = [nan '1' '88' '0' 0 88]\n",
      "No. of NaN values in numeracy6_ut_q6 = 1013\n",
      "No. of UNDEFINED values in numeracy6_ut_q6 = 0\n",
      "No. of SKIPPED values in numeracy6_ut_q6 = 0\n",
      "\n",
      "Unique values in numeracy6_ut_q7 = [nan '1' '88' '0' 1 0 88]\n",
      "No. of NaN values in numeracy6_ut_q7 = 1134\n",
      "No. of UNDEFINED values in numeracy6_ut_q7 = 0\n",
      "No. of SKIPPED values in numeracy6_ut_q7 = 0\n",
      "\n",
      "Unique values in numeracy6_ut_q8 = [nan '1' '88' '0' 0 88]\n",
      "No. of NaN values in numeracy6_ut_q8 = 1190\n",
      "No. of UNDEFINED values in numeracy6_ut_q8 = 0\n",
      "No. of SKIPPED values in numeracy6_ut_q8 = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "numeracy6_raw = [col for col in numeracy6 if re.search(r'numeracy6.+\\d$', col)]\n",
    "for col in numeracy6_raw:\n",
    "    print(f\"Unique values in {col} = {mp_numeracy[col].unique()}\")\n",
    "    print(f\"No. of NaN values in {col} = {mp_numeracy.loc[:, col].isna().sum()}\")\n",
    "    print(f\"No. of UNDEFINED values in {col} = {mp_numeracy[mp_numeracy[col] == 'UNDEFINED'].shape[0]}\")    \n",
    "    print(f\"No. of SKIPPED values in {col} = {mp_numeracy[mp_numeracy[col] == 'SKIPPED'].shape[0]}\\n\")\n",
    "    mp_numeracy.loc[:, col].fillna('999', inplace=True)\n",
    "    mp_numeracy[col].replace('UNDEFINED', '999', inplace=True)\n",
    "    mp_numeracy[col].replace('SKIPPED', '999', inplace=True)\n",
    "    mp_numeracy[col].replace('.', '999', inplace=True)\n",
    "    mp_numeracy.loc[:, col] = mp_numeracy.loc[:, col].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72883832",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 7: Subtraction\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "edec0e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in numeracy7_ut_q1 = ['88' '0' '1' 1 88 0]\n",
      "No. of NaN values in numeracy7_ut_q1 = 0\n",
      "No. of UNDEFINED values in numeracy7_ut_q1 = 0\n",
      "No. of SKIPPED values in numeracy7_ut_q1 = 0\n",
      "\n",
      "Unique values in numeracy7_ut_q2 = ['88' '0' '1' 0 88 1]\n",
      "No. of NaN values in numeracy7_ut_q2 = 0\n",
      "No. of UNDEFINED values in numeracy7_ut_q2 = 0\n",
      "No. of SKIPPED values in numeracy7_ut_q2 = 0\n",
      "\n",
      "Unique values in numeracy7_ut_q3 = ['88' '0' '1' 0 88]\n",
      "No. of NaN values in numeracy7_ut_q3 = 0\n",
      "No. of UNDEFINED values in numeracy7_ut_q3 = 0\n",
      "No. of SKIPPED values in numeracy7_ut_q3 = 0\n",
      "\n",
      "Unique values in numeracy7_ut_q4 = ['88' '0' '1' 1 88 0]\n",
      "No. of NaN values in numeracy7_ut_q4 = 0\n",
      "No. of UNDEFINED values in numeracy7_ut_q4 = 0\n",
      "No. of SKIPPED values in numeracy7_ut_q4 = 0\n",
      "\n",
      "Unique values in numeracy7_ut_q5 = [nan '0' '1' '88' 0]\n",
      "No. of NaN values in numeracy7_ut_q5 = 1051\n",
      "No. of UNDEFINED values in numeracy7_ut_q5 = 0\n",
      "No. of SKIPPED values in numeracy7_ut_q5 = 0\n",
      "\n",
      "Unique values in numeracy7_ut_q6 = [nan '0' '88' '1' 1 0 88]\n",
      "No. of NaN values in numeracy7_ut_q6 = 1109\n",
      "No. of UNDEFINED values in numeracy7_ut_q6 = 0\n",
      "No. of SKIPPED values in numeracy7_ut_q6 = 0\n",
      "\n",
      "Unique values in numeracy7_ut_q7 = [nan '0' '88' '1' 0]\n",
      "No. of NaN values in numeracy7_ut_q7 = 1247\n",
      "No. of UNDEFINED values in numeracy7_ut_q7 = 0\n",
      "No. of SKIPPED values in numeracy7_ut_q7 = 0\n",
      "\n",
      "Unique values in numeracy7_ut_q8 = [nan '88' '0' '1' 0]\n",
      "No. of NaN values in numeracy7_ut_q8 = 1278\n",
      "No. of UNDEFINED values in numeracy7_ut_q8 = 0\n",
      "No. of SKIPPED values in numeracy7_ut_q8 = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "numeracy7_raw = [col for col in numeracy7 if re.search(r'numeracy7.+\\d$', col)]\n",
    "for col in numeracy7_raw:\n",
    "    print(f\"Unique values in {col} = {mp_numeracy[col].unique()}\")\n",
    "    print(f\"No. of NaN values in {col} = {mp_numeracy.loc[:, col].isna().sum()}\")\n",
    "    print(f\"No. of UNDEFINED values in {col} = {mp_numeracy[mp_numeracy[col] == 'UNDEFINED'].shape[0]}\")    \n",
    "    print(f\"No. of SKIPPED values in {col} = {mp_numeracy[mp_numeracy[col] == 'SKIPPED'].shape[0]}\\n\")\n",
    "    mp_numeracy.loc[:, col].fillna('999', inplace=True)\n",
    "    mp_numeracy[col].replace('UNDEFINED', '999', inplace=True)\n",
    "    mp_numeracy[col].replace('SKIPPED', '999', inplace=True)\n",
    "    mp_numeracy[col].replace('.', '999', inplace=True)\n",
    "    mp_numeracy.loc[:, col] = mp_numeracy.loc[:, col].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ab73d3",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 8: Word Problems\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "448ec807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in numeracy8_ut_q1 = ['1' '88' '0' 1 88 0]\n",
      "No. of NaN values in numeracy8_ut_q1 = 0\n",
      "No. of UNDEFINED values in numeracy8_ut_q1 = 0\n",
      "No. of SKIPPED values in numeracy8_ut_q1 = 0\n",
      "\n",
      "Unique values in numeracy8_ut_q2 = ['88' '1' '0' 0 1 88]\n",
      "No. of NaN values in numeracy8_ut_q2 = 0\n",
      "No. of UNDEFINED values in numeracy8_ut_q2 = 0\n",
      "No. of SKIPPED values in numeracy8_ut_q2 = 0\n",
      "\n",
      "Unique values in numeracy8_ut_q3 = ['1' '88' '0' 0 88 1]\n",
      "No. of NaN values in numeracy8_ut_q3 = 0\n",
      "No. of UNDEFINED values in numeracy8_ut_q3 = 0\n",
      "No. of SKIPPED values in numeracy8_ut_q3 = 0\n",
      "\n",
      "Unique values in numeracy8_ut_q4 = ['0' '1' '88' 0 88 1]\n",
      "No. of NaN values in numeracy8_ut_q4 = 0\n",
      "No. of UNDEFINED values in numeracy8_ut_q4 = 0\n",
      "No. of SKIPPED values in numeracy8_ut_q4 = 0\n",
      "\n",
      "Unique values in numeracy8_ut_q5 = ['0' nan '88' '1' 1 0 88]\n",
      "No. of NaN values in numeracy8_ut_q5 = 844\n",
      "No. of UNDEFINED values in numeracy8_ut_q5 = 0\n",
      "No. of SKIPPED values in numeracy8_ut_q5 = 0\n",
      "\n",
      "Unique values in numeracy8_ut_q6 = ['0' nan '88' '1' 1 0 88]\n",
      "No. of NaN values in numeracy8_ut_q6 = 989\n",
      "No. of UNDEFINED values in numeracy8_ut_q6 = 0\n",
      "No. of SKIPPED values in numeracy8_ut_q6 = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "numeracy8_raw = [col for col in numeracy8 if re.search(r'numeracy8.+\\d$', col)]\n",
    "for col in numeracy8_raw:\n",
    "    print(f\"Unique values in {col} = {mp_numeracy[col].unique()}\")\n",
    "    print(f\"No. of NaN values in {col} = {mp_numeracy.loc[:, col].isna().sum()}\")\n",
    "    print(f\"No. of UNDEFINED values in {col} = {mp_numeracy[mp_numeracy[col] == 'UNDEFINED'].shape[0]}\")    \n",
    "    print(f\"No. of SKIPPED values in {col} = {mp_numeracy[mp_numeracy[col] == 'SKIPPED'].shape[0]}\\n\")\n",
    "    mp_numeracy.loc[:, col].fillna('999', inplace=True)\n",
    "    mp_numeracy[col].replace('UNDEFINED', '999', inplace=True)\n",
    "    mp_numeracy[col].replace('SKIPPED', '999', inplace=True)\n",
    "    mp_numeracy[col].replace('.', '999', inplace=True)\n",
    "    mp_numeracy.loc[:, col] = mp_numeracy.loc[:, col].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4800add3",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 9a: Shape Recognition (Circle)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ffee6f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in numeracy9a_ut_grid_1 = ['1' '0' 'UNDEFINED' 1 0]\n",
      "No. of NaN values in numeracy9a_ut_grid_1 = 0\n",
      "No. of UNDEFINED values in numeracy9a_ut_grid_1 = 2\n",
      "No. of SKIPPED values in numeracy9a_ut_grid_1 = 0\n",
      "\n",
      "Unique values in numeracy9a_ut_grid_2 = ['1' '0' 'UNDEFINED' 1 0]\n",
      "No. of NaN values in numeracy9a_ut_grid_2 = 0\n",
      "No. of UNDEFINED values in numeracy9a_ut_grid_2 = 2\n",
      "No. of SKIPPED values in numeracy9a_ut_grid_2 = 0\n",
      "\n",
      "Unique values in numeracy9a_ut_grid_3 = ['1' '0' 'UNDEFINED' 1 0]\n",
      "No. of NaN values in numeracy9a_ut_grid_3 = 0\n",
      "No. of UNDEFINED values in numeracy9a_ut_grid_3 = 2\n",
      "No. of SKIPPED values in numeracy9a_ut_grid_3 = 0\n",
      "\n",
      "Unique values in numeracy9a_ut_grid_4 = ['0' '1' 'UNDEFINED' 1 0]\n",
      "No. of NaN values in numeracy9a_ut_grid_4 = 0\n",
      "No. of UNDEFINED values in numeracy9a_ut_grid_4 = 2\n",
      "No. of SKIPPED values in numeracy9a_ut_grid_4 = 0\n",
      "\n",
      "Unique values in numeracy9a_ut_grid_5 = ['1' '0' 'UNDEFINED' 1 0]\n",
      "No. of NaN values in numeracy9a_ut_grid_5 = 0\n",
      "No. of UNDEFINED values in numeracy9a_ut_grid_5 = 2\n",
      "No. of SKIPPED values in numeracy9a_ut_grid_5 = 0\n",
      "\n",
      "Unique values in numeracy9a_ut_grid_6 = ['1' '0' 'UNDEFINED' 1 0]\n",
      "No. of NaN values in numeracy9a_ut_grid_6 = 0\n",
      "No. of UNDEFINED values in numeracy9a_ut_grid_6 = 2\n",
      "No. of SKIPPED values in numeracy9a_ut_grid_6 = 0\n",
      "\n",
      "Unique values in numeracy9a_ut_grid_7 = ['1' '0' 'UNDEFINED' 1 0]\n",
      "No. of NaN values in numeracy9a_ut_grid_7 = 0\n",
      "No. of UNDEFINED values in numeracy9a_ut_grid_7 = 2\n",
      "No. of SKIPPED values in numeracy9a_ut_grid_7 = 0\n",
      "\n",
      "Unique values in numeracy9a_ut_grid_8 = ['1' '0' 'UNDEFINED' 1 0]\n",
      "No. of NaN values in numeracy9a_ut_grid_8 = 0\n",
      "No. of UNDEFINED values in numeracy9a_ut_grid_8 = 2\n",
      "No. of SKIPPED values in numeracy9a_ut_grid_8 = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "numeracy9a_raw = [col for col in numeracy9a if re.search(r'numeracy9a_ut_grid_', col)]\n",
    "for col in numeracy9a_raw:\n",
    "    print(f\"Unique values in {col} = {mp_numeracy[col].unique()}\")\n",
    "    print(f\"No. of NaN values in {col} = {mp_numeracy.loc[:, col].isna().sum()}\")\n",
    "    print(f\"No. of UNDEFINED values in {col} = {mp_numeracy[mp_numeracy[col] == 'UNDEFINED'].shape[0]}\")    \n",
    "    print(f\"No. of SKIPPED values in {col} = {mp_numeracy[mp_numeracy[col] == 'SKIPPED'].shape[0]}\\n\")\n",
    "    mp_numeracy[col].replace('UNDEFINED', '0', inplace=True)\n",
    "    mp_numeracy.loc[:, col] = mp_numeracy.loc[:, col].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6fb97",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 9b: Shape Recognition (Rectangle)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a0f1e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in numeracy9b_ut_grid_1 = ['1' '0' 1 0]\n",
      "No. of NaN values in numeracy9b_ut_grid_1 = 0\n",
      "No. of UNDEFINED values in numeracy9b_ut_grid_1 = 0\n",
      "No. of SKIPPED values in numeracy9b_ut_grid_1 = 0\n",
      "\n",
      "Unique values in numeracy9b_ut_grid_2 = ['1' '0' 0 1]\n",
      "No. of NaN values in numeracy9b_ut_grid_2 = 0\n",
      "No. of UNDEFINED values in numeracy9b_ut_grid_2 = 0\n",
      "No. of SKIPPED values in numeracy9b_ut_grid_2 = 0\n",
      "\n",
      "Unique values in numeracy9b_ut_grid_3 = ['0' '1' 1 0]\n",
      "No. of NaN values in numeracy9b_ut_grid_3 = 0\n",
      "No. of UNDEFINED values in numeracy9b_ut_grid_3 = 0\n",
      "No. of SKIPPED values in numeracy9b_ut_grid_3 = 0\n",
      "\n",
      "Unique values in numeracy9b_ut_grid_4 = ['1' '0' 1 0]\n",
      "No. of NaN values in numeracy9b_ut_grid_4 = 0\n",
      "No. of UNDEFINED values in numeracy9b_ut_grid_4 = 0\n",
      "No. of SKIPPED values in numeracy9b_ut_grid_4 = 0\n",
      "\n",
      "Unique values in numeracy9b_ut_grid_5 = ['1' '0' 0 1]\n",
      "No. of NaN values in numeracy9b_ut_grid_5 = 0\n",
      "No. of UNDEFINED values in numeracy9b_ut_grid_5 = 0\n",
      "No. of SKIPPED values in numeracy9b_ut_grid_5 = 0\n",
      "\n",
      "Unique values in numeracy9b_ut_grid_6 = ['1' '0' 1 0]\n",
      "No. of NaN values in numeracy9b_ut_grid_6 = 0\n",
      "No. of UNDEFINED values in numeracy9b_ut_grid_6 = 0\n",
      "No. of SKIPPED values in numeracy9b_ut_grid_6 = 0\n",
      "\n",
      "Unique values in numeracy9b_ut_grid_7 = ['1' '0' 1 0]\n",
      "No. of NaN values in numeracy9b_ut_grid_7 = 0\n",
      "No. of UNDEFINED values in numeracy9b_ut_grid_7 = 0\n",
      "No. of SKIPPED values in numeracy9b_ut_grid_7 = 0\n",
      "\n",
      "Unique values in numeracy9b_ut_grid_8 = ['1' '0' 1 0]\n",
      "No. of NaN values in numeracy9b_ut_grid_8 = 0\n",
      "No. of UNDEFINED values in numeracy9b_ut_grid_8 = 0\n",
      "No. of SKIPPED values in numeracy9b_ut_grid_8 = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data for'UNDEFINED' or 'SKIPPED' values\n",
    "numeracy9b_raw = [col for col in numeracy9b if re.search(r'numeracy9b_ut_grid_', col)]\n",
    "for col in numeracy9b_raw:\n",
    "    print(f\"Unique values in {col} = {mp_numeracy[col].unique()}\")\n",
    "    print(f\"No. of NaN values in {col} = {mp_numeracy.loc[:, col].isna().sum()}\")\n",
    "    print(f\"No. of UNDEFINED values in {col} = {mp_numeracy[mp_numeracy[col] == 'UNDEFINED'].shape[0]}\")    \n",
    "    print(f\"No. of SKIPPED values in {col} = {mp_numeracy[mp_numeracy[col] == 'SKIPPED'].shape[0]}\\n\")\n",
    "    mp_numeracy[col].replace('UNDEFINED', '0', inplace=True)\n",
    "    mp_numeracy.loc[:, col] = mp_numeracy.loc[:, col].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8eb3ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_numeracy.to_excel(\"mp_raw_numeracy_full.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c9590b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902e132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
